# Multiproject Research - Nova単体 IRL vs RF 比較

## 📚 ドキュメント一覧

### 主要ドキュメント

1. **[IRL実装の完全ガイド](outputs/analysis_data/IRL_IMPLEMENTATION_COMPLETE_GUIDE.md)** ⭐⭐⭐
   - IRLの訓練・評価プロセスの詳細説明
   - スライディングウィンドウによる訓練サンプル生成
   - 評価データ作成の履歴期間ロジック
   - サンプル数決定メカニズム
   - 具体例で理解する

2. **[RFベースライン 案1 vs 案2 比較](outputs/analysis_data/RF_BASELINE_COMPARISON.md)** ⭐⭐⭐
   - 案1: IRL完全再現アプローチ (複雑・厳密)
   - 案2: シンプルベースラインアプローチ (簡単・実用的)
   - 詳細比較表と実装例
   - 推奨アプローチ: まず案2から

3. **[IRL vs RF 実装の不一致点](outputs/analysis_data/IRL_vs_RF_INCONSISTENCIES.md)** ⭐⭐
   - 初期調査で発見した不一致
   - データソース、ラベル定義、除外ロジックの違い
   - 修正すべき点のリスト

### 結果ディレクトリ

#### IRL結果
- **ディレクトリ**: `results/review_continuation_cross_eval_nova/`
- **README**: [results/review_continuation_cross_eval_nova/README.md](results/review_continuation_cross_eval_nova/README.md)
- **評価パターン**: 16通り (4訓練 × 4評価)
- **期間**: 訓練 2021-2023, 評価 2023-2024
- **平均AUC-ROC**: 0.754
- **最高AUC-ROC**: 0.910 (train: 0-3m, eval: 6-9m)

#### RF結果 (修正版v2)
- **ディレクトリ**: `outputs/rf_nova_10patterns_irl_aligned_v2/`
- **評価パターン**: 10通り (対角線+クロス評価)
- **実装状態**: ⚠️ **サンプル数がIRLと不一致** (要修正)
  - RF 0-3m→0-3m: 79サンプル (IRL: 60サンプル)
  - RF 6-9m→6-9m: 81サンプル (IRL: 42サンプル)
- **平均AUC-ROC**: 0.9328 (高すぎる - データリークの可能性)

## 🔍 現状の問題点

### 1. 評価期間の不一致 ❌
**問題**: RFは評価期間を2021年に設定しているが、IRLは2023年を使用

**正しい期間**:
- 訓練期間: 2021-01-01 ~ 2022-01-01
  - 0-3m: 2021-01-01 ~ 2021-04-01
  - 3-6m: 2021-04-01 ~ 2021-07-01
  - 6-9m: 2021-07-01 ~ 2021-10-01
  - 9-12m: 2021-10-01 ~ 2022-01-01
- **評価期間**: 2023-01-01 ~ 2024-01-01 ⚠️
  - 0-3m: 2023-01-01 ~ 2023-04-01
  - 3-6m: 2023-04-01 ~ 2023-07-01
  - 6-9m: 2023-07-01 ~ 2023-10-01
  - 9-12m: 2023-10-01 ~ 2024-01-01

### 2. 履歴期間の不一致 ❓
**問題**: 評価時の履歴期間の計算方法が不明確

**仮説1**: 訓練終了日から12ヶ月前
```
train 0-3m (cutoff=2021-04-01)
→ history: 2020-04-01 ~ 2021-04-01
```

**仮説2**: 評価開始日から12ヶ月前
```
eval 0-3m (2023-01-01~2023-04-01)
→ history: 2022-01-01 ~ 2023-01-01
```

**IRLの観察結果**:
- 同じ評価窓のサンプル数は、訓練窓に関わらず**常に一貫**
- eval 0-3m: 60サンプル (全訓練窓で同じ)
- eval 3-6m: 55サンプル (全訓練窓で同じ)

**結論**: 仮説2が正しい可能性が高い (要コード確認)

### 3. 訓練データの作成方法 🔄
**問題**: RFはスライディングウィンドウを使用していない

**IRLの訓練方法**:
- 2019-01-01 ~ 2021-04-01の長期間データを使用
- 月次でスライディングウィンドウ
- 各時点で: 過去12ヶ月の履歴 → 0-3m先のラベル
- 総訓練サンプル数: ~1000サンプル

**現在のRF**:
- 単一期間からサンプル生成
- 訓練サンプル数: 60-80サンプル
- 訓練データが大幅に少ない

## 📋 次のアクション

### 優先度1: 評価期間を修正
- [ ] 評価期間を2021年 → 2023年に変更
- [ ] 10パターン全て再実行
- [ ] サンプル数がIRLと一致するか確認

### 優先度2: 履歴期間の計算を確認
- [ ] IRLのコードまたはログで実際の履歴期間を確認
- [ ] 仮説1 vs 仮説2のどちらが正しいか判定
- [ ] RFに正しいロジックを実装

### 優先度3: 訓練データの方針決定
- [ ] 案1 (IRL完全再現) vs 案2 (シンプル) を選択
- [ ] 推奨: まず案2を実装して結果を確認
- [ ] 必要に応じて案1に拡張

## 🎯 期待される結果

### サンプル数の一致 (目標)

| 評価窓 | IRL | RF (修正後) |
|--------|-----|------------|
| 0-3m | 60 | 60 |
| 3-6m | 55 | 55 |
| 6-9m | 42 | 42 |
| 9-12m | 39 | 39 |

### 性能比較 (予想)

**案2 (シンプルベースライン) を使用した場合**:

| メトリクス | IRL | RF (予想) |
|-----------|-----|----------|
| 平均AUC-ROC | 0.754 | 0.70-0.80 |
| 最高AUC-ROC | 0.910 | 0.75-0.85 |
| 平均F1 | 0.645 | 0.60-0.70 |

**期待される結果**:
- RFはIRLに近い性能を示す
- 一部のパターンでRFがIRLを上回る可能性
- IRLの時系列学習の優位性が確認される

## 📊 データ構造

### ディレクトリ構造

```
multiproject_research/
├── data/
│   └── review_requests_openstack_multi_5y_detail.csv  # Nova単体データ
│
├── results/
│   └── review_continuation_cross_eval_nova/  # IRL結果 (16パターン)
│       ├── README.md
│       ├── matrix_*.csv
│       └── train_*/eval_*/
│
├── outputs/
│   ├── rf_nova_10patterns_irl_aligned_v2/  # RF結果 (10パターン、要修正)
│   │   ├── all_results.json
│   │   └── matrix_*.csv
│   │
│   └── analysis_data/  # 分析ドキュメント
│       ├── IRL_IMPLEMENTATION_COMPLETE_GUIDE.md  ⭐⭐⭐
│       ├── RF_BASELINE_COMPARISON.md  ⭐⭐⭐
│       └── IRL_vs_RF_INCONSISTENCIES.md  ⭐⭐
│
└── scripts/
    ├── train/
    │   └── train_model.py  # IRLモデル訓練
    │
    └── analysis/
        └── rf_nova_10patterns_irl_aligned_v2.py  # RFベースライン (要修正)
```

## 🔧 実装スクリプト

### IRL訓練スクリプト
```bash
# Nova単体のクロス時間評価 (既に完了)
uv run python scripts/train/train_model.py \
  --reviews data/review_requests_openstack_multi_5y_detail.csv \
  --project openstack/nova \
  --train-start 2021-01-01 \
  --train-end 2023-01-01 \
  --eval-start 2023-01-01 \
  --eval-end 2024-01-01 \
  --output results/review_continuation_cross_eval_nova
```

### RF評価スクリプト (修正版)
```bash
# 修正後に再実行予定
uv run python scripts/analysis/rf_nova_10patterns_irl_aligned_v2.py
```

## 📝 重要な発見

### 1. IRLのサンプル数の一貫性
同じ評価窓のサンプル数は、訓練窓に関わらず常に同じ:
- これは、評価時の履歴期間が訓練窓に依存していないことを示唆
- 履歴期間 = 評価開始日 - 12ヶ月の可能性が高い

### 2. RFの高すぎる性能
現在のRF結果 (AUC-ROC 0.93) は高すぎる:
- データリークの可能性
- 評価期間が訓練期間と重複している
- 評価期間を2023年に変更すれば改善されるはず

### 3. 訓練データの重要性
IRLは長期間データからスライディングウィンドウで訓練:
- 時系列の変化を学習
- 多様な状況での開発者行動を学習
- RFもこれを再現すべきか、シンプルなベースラインで良いか要検討

## 🚀 研究の目的

### 主要な研究質問
1. **RQ1**: Random ForestベースラインはIRLに対してどの程度の性能を示すか？
2. **RQ2**: IRLの時系列学習は、静的なRFと比較して有効か？
3. **RQ3**: どの評価パターン (0-3m, 3-6m, 6-9m, 9-12m) で最も性能差が大きいか？

### 期待される貢献
1. IRLモデルの有効性の実証
2. 時系列学習の重要性の定量化
3. レビュアー継続予測における最適な時間窓の特定

## 📅 更新履歴

- **2025-12-19**: 初期分析完了、IRLとRFの不一致を発見
- **2025-12-19**: IRL実装の完全ガイド作成
- **2025-12-19**: RFベースライン2案の比較ドキュメント作成
- **2025-12-19**: 評価期間の不一致を発見 (2021 vs 2023)

## 📧 連絡先

研究に関する質問は、プロジェクトのGitHubリポジトリでIssueを作成してください。

---

**Last Updated**: 2025-12-19
**Status**: 🚧 実装修正中 - 評価期間とサンプル数の不一致を修正予定
