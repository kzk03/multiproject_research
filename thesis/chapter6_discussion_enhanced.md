# 第6章 考察（拡張版）

## 6.1 時系列データの考慮が予測に与える影響

図\ref{fig:IRLheatmap}から，IRLにおいて，訓練期間が3-6mであるモデルと，他の訓練期間のモデルと比較してAUC-ROCが平均的に高くなることがわかる．これは分析対象とするnovaプロジェクトが6ヶ月ごとにリリースしていることが一要因として考えられる．また図\ref{fig:IRLheatmap}，図\ref{fig:RFheatmap}から，RFはIRLと比較して，AUC-ROCの最大値が0.928であり，IRLの最大値である0.910より高くなることがわかった．
しかし，IRLはRFと比較し，評価期間が6-9mの場合を除いたすべてのパターンでAUC-ROCが高くなることが明らかになった．

これらのことから，RFはIRLに比べ高い精度を出すことができ，学習したパターンにうまく当てはまる評価期間では高い精度が出るが，
IRLでは，時系列的な開発者の行動パターンやプロジェクトの特性をうまく学習するため，最大値では劣るものの，多くの評価パターンでRFの精度を上回ることができると考えられる．

また，図\ref{fig:acceptance_bins}は，評価期間ごとの承諾率の階級の構成比を示している．
評価期間内のレビュアーの承諾率の分布を確認すると，期間ごとにレビュアーの承諾率の分布が大きく変化している．
例えば，3-6mでは承諾率0–10%の層が38.1%と最多であるのに対し，9-12mでは70–100%の層が55.6%と過半数を占めることがわかる．
このように，低承諾が多数派の期間から高承諾が多数派の期間へと分布が移動しており，単一時点の特徴量だけでは捉えにくい変化が存在することが考えられる．
時系列的な変化を軌跡として学習するIRLは，こうした分布の移動を反映しやすく，複数期間で安定的に精度を確保できた理由の一つと考えられる．

\begin{figure}[h]
	\centering
	\includegraphics[width=0.85\textwidth]{./Hashimoto_fig/acceptance_rate_bins_stacked.pdf}
	\caption{承諾率階級の構成比の推移（レビュアー単位）}
	\label{fig:acceptance_bins}
\end{figure}

## 6.2 短期予測と長期予測における特徴量の違い

図\ref{fig:IRLimportance}に示す通り，IRLにおいて各モデルにおいて寄与する特徴量の変化が確認され，初期段階では総レビュー依頼数やレビュー数などの活動量が予測に大きく寄与したが，期間が進むにつれてその影響が減少し，協力度や活動間隔やレビュー強度といった活動量以外の要因の寄与が高まった．これは，0-3mのモデルで，予測区間が9-12mにまで離れると，活動量を重視した予測を行うが，活動量以外の特徴量も重要となるために，予測精度が低下する原因になると考えられる．

図\ref{fig:request_acceptance_boxplot}は，評価期間ごとのレビュー依頼数・承諾率・応答速度の分布を示している．
レビュー依頼数の中央値は各期間を通じてほぼ一定であり，活動量の規模に大きな変化は見られない．
一方で，承諾率の中央値は0-3mの0.500から9-12mの0.773へと上昇しており，分布全体が高承諾側へ移動している．
さらに，応答日数の中央値は0-3mの6.25日から9-12mの4.5日へと短縮しており，後半期間ではレビュアーの応答速度が向上していることがわかる．
これらの結果は，活動量の規模が同程度であっても，「承諾率や応答の速さ」といった質的側面が期間とともに変化していることを示す．

\begin{figure}[h]
	\centering
	\includegraphics[width=0.95\textwidth]{./Hashimoto_fig/request_acceptance_boxplot.pdf}
	\caption{評価期間別のレビュー依頼数・承諾率・応答速度の分布（レビュアー単位）}
	\label{fig:request_acceptance_boxplot}
\end{figure}

これらの結果から，短期間の予測では活動量による影響が強く，長期間になるにつれて協力度や応答速度といった行動の量ではなく質的な要因の影響が高くなると考える．また，レビュー規模，先月の活動回数と比較した活動回数の上昇率である活動トレンドは，一貫して負の影響を示し，レビュー負荷も負の値であるモデルが多いことから，レビュー規模や回数がかかり過ぎるとレビュアーへの負担が増加し，離脱の要因となることが示唆される．また平均活動間隔においても一貫して負の影響を示し，活動間隔が増加することもレビュアーの離脱の要因となることが示唆される．

以上の結果は，短期では活動量が効き，長期では質的特徴量が効くというRQ3の結論を，分布推移の観点から補強するものである．

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.85\textwidth]{./Hashimoto_fig/median_trends.pdf}
	\caption{承諾率中央値と応答遅延中央値の推移}
	\label{fig:median_trends}
\end{figure}

## 6.3 IRL/RFにおいて予測不一致の開発者について

図\ref{fig:venn_diagram}に，IRLとRFの正解パターンをベン図で示す．
10パターンの訓練・評価期間の組み合わせにおいて，各パターン39〜60名のレビュアーを対象に予測を行い，延べ452件の予測結果を得た．IRLとRFの予測結果を比較すると，両手法が一致して正解した件数は216件（47.8\%），IRLのみが正解した件数は122件（27.0\%），RFのみが正解した件数は69件（15.3\%），両方不正解は45件（10.0\%）であった．IRLのみ正解はRFのみ正解の約1.8倍であり，IRLが単独で正しく予測するケースが多いことが確認された．以下では，一方のみが正解した事例の特徴を分析し，各手法の強みと限界を考察する．

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{./Hashimoto_fig/discussion/venn_irl_rf.pdf}
	\caption{IRLとRFの正解パターンのベン図}
	\label{fig:venn_diagram}
\end{figure}

### 承諾率が低いレビュアーの離脱予測
IRLのみが正解した13人の開発者を活動量と承諾率で分類した結果，
50\%以上（6人）がHeavy-Mid（多依頼・中承諾率），
38\%（5人）がHeavy-Low（多依頼・低承諾率）に分類された（図\ref{fig:developer_matrix}）．

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{./Hashimoto_fig/discussion/heatmap_2x2.pdf}
	\caption{活動量と承諾率による開発者分類}
	\label{fig:developer_matrix}
\end{figure}

IRLのみが正解した122件のうち，実際には離脱したにもかかわらずRFが誤って承諾と予測した事例は96件であった．これらのレビュアーの平均履歴数は128.7件，平均承諾率は0.138であった．
例えば，あるレビュアーは履歴数が563件であるが承諾率は0.005と極めて低く，RFは予測確率0.65で承諾と予測したのに対し，IRLは正しく離脱と予測した．
これは，RFが特徴量の単一時点での組み合わせに基づき誤って承諾と予測した一方，IRLは承諾率の低さや活動パターンの時系列的な変化を捉えることで，正しく離脱を予測できたと考えられる．

### RFが閾値付近で誤判定したレビュアーの承諾予測
IRLのみが正解した122件のうち，実際には承諾したにもかかわらずRFが誤って離脱と予測した事例は26件であった．これらのレビュアーについてRFの予測確率の平均は0.43〜0.51と閾値（0.5）付近であり，RFの判定が不安定であった．
一方，IRLは時系列での活動パターンを考慮し，正しく承諾と予測することができた．

### RFのみが正解したケースにおける特徴
RFのみが正解した69件のうち，実際には承諾したにもかかわらずIRLが誤って離脱と予測した事例は35件であった．これらのレビュアーの平均履歴数は217.0件，平均承諾率は0.192であった．
代表的な事例では，あるレビュアーは10パターン中9パターンでRFのみが正解しており，RFは予測確率0.63で正しく承諾と予測した一方，IRLの予測確率は0.46付近と閾値に近く一貫して離脱と誤予測した．
これは，活動量と承諾率の両方が中程度であるケースでは，RFの特徴量ベースの分類が有効に機能する一方，IRLは時系列上の明確な傾向を抽出しにくく，予測が不安定になりうることを示唆している．

## 6.4 Random ForestとIRLの学習メカニズムの本質的違い

RQ4で明らかになったRFとIRLの劇的な順位逆転（最大12ランク）は，両モデルの**学習メカニズムの本質的な違い**を反映している．

### 6.4.1 なぜ逆転が起きるのか

**ケース1: 応答速度（RF 1位 → IRL 11位）**

- **RFの視点**: 過去データで「応答が速い人は継続率が高い」という**静的な相関**を発見 → Gini分岐で最優先（26.61%）
- **IRLの視点**: 応答速度の**変化**が将来報酬に与える**因果的影響**は限定的 → 勾配値+0.0027（小さい）

**解釈**: RFは過去の統計パターン（応答が速い人＝継続しやすい）を学習しているが，IRLは「応答速度を変化させる行動」の因果的影響を評価している．応答速度は個人特性で変更しにくいため，IRLでは重要度が低い．

**ケース2: 協力度（RF 14位 → IRL 2位）**

- **RFの視点**: 訓練データで協力度が決定境界にならない → Gini分岐に使われず重要度0%
- **IRLの視点**: 協力的な行動を取ることが**最適方策**の一部（報酬最大化に直結） → 勾配値+0.0131（大きい）

**解釈**: RFは過去データで協力度が継続/離脱の判別に使われなかったため無視したが，IRLは「協力的な行動を選択すること」が将来の継続報酬を最大化すると学習した．

### 6.4.2 学習対象の違い

**表 6.1: RFとIRLの学習対象の比較**

| 観点 | Random Forest | IRL (LSTM) |
|------|--------------|------------|
| **学習対象** | 過去データの**静的パターン** | 行動系列の**動的な因果関係** |
| **特徴選択** | Gini係数（情報利得）による分岐 | 勾配ベース（報酬への影響度） |
| **時系列考慮** | なし（各時点独立） | あり（LSTMで系列学習） |
| **解釈** | 相関関係 | 因果的影響 |
| **重要度の意味** | 過去の統計的な判別貢献度 | 行動変化が報酬に与える影響 |

### 6.4.3 行動特徴 vs 状態特徴

RQ4の結果から，RFとIRLで重視する特徴のカテゴリにも違いがあることが明らかになった：

**RFが重視**:
- **状態特徴（State）**: 応答速度、総レビュー数、最近の活動頻度
- 「どのような状態の人が継続しやすいか」を学習

**IRLが重視**:
- **行動特徴（Action）**: 協力度、強度（ファイル数）、総コミット数
- 「どのような行動を選択すると継続しやすくなるか」を学習

この違いは，**RFが「継続する人の特徴」を識別するのに対し，IRLが「継続するための行動」を学習している**ことを示唆している．

## 6.5 モデル選択が解釈に与える影響

RQ4の結果は，**特徴量重要度の解釈がモデル選択に強く依存する**という重要な示唆を与える．

### 6.5.1 同じデータでも異なる結論

同じOpenStack/Novaデータを用いても：

- **RFの結論**: 「応答速度が速く、総レビュー数が多い人を選ぶべき」
- **IRLの結論**: 「協力的な行動を促し、活動間隔を短く保つべき」

この2つの結論は**矛盾しないが、実務的な施策は大きく異なる**：

| 観点 | RFベースの施策 | IRLベースの施策 |
|------|---------------|----------------|
| **アプローチ** | 継続しやすい人を選抜 | 継続しやすい行動を促進 |
| **具体策** | 応答速度、実績で選考 | ペアレビュー、定期的関与 |
| **介入可能性** | 低い（個人特性） | 高い（行動変容可能） |
| **持続可能性** | 人材依存 | 組織的な仕組み |

### 6.5.2 研究への示唆

本研究の発見は，ソフトウェア工学研究において**特徴量重要度を報告する際の注意点**を提起する：

1. **モデルの学習メカニズムを明記**: 「Gini係数ベース」「勾配ベース」など
2. **重要度の意味を解釈**: 「相関」なのか「因果」なのか
3. **複数モデルでの検証**: 単一モデルに依存しない
4. **実務的含意の慎重な検討**: 介入可能性を考慮

## 6.6 実務的含意：レビュア継続を促進するには

RQ4の結果から，レビュア継続を促進する実務的な施策を提案できる．

### 6.6.1 IRLベースの推奨施策（因果ベース）

IRLモデルが示す**介入可能な因果関係**に基づく施策：

**1. 協力度を高める（最重要: 勾配+0.0131）**
- ペアレビュー制度の導入
- メンタープログラムの実施
- 協力的なレビューに対するインセンティブ

**2. 活動間隔を短く保つ（勾配-0.0107）**
- 定期的なレビュー依頼の仕組み
- 3ヶ月以上の空白期間に警告
- 軽量なタスクで関与を維持

**3. レビュー負荷の管理（勾配-0.0034）**
- 大規模レビュー（行数多い）の分割
- レビュー負荷の可視化と分散
- 負荷が高いレビュアーへのサポート

**4. コード品質の維持（勾配-0.0078）**
- コード品質ガイドラインの整備
- 品質低下時のアラート
- 品質向上のための教育

### 6.6.2 RFベースの推奨施策（相関ベース）

RFモデルが示す**統計的相関**に基づく施策：

**1. 応答速度が速い人を優先選抜**
- 過去の応答速度データでスクリーニング
- ただし**個人特性のため変更困難**

**2. 総レビュー数が多い人を継続候補とする**
- 実績ベースの評価
- ただし**過去の実績が将来を保証しない**

### 6.6.3 IRLの方が実務的に有用な理由

IRLベースの施策が実務的に優れている理由：

1. **介入可能性**: 「協力度を上げる」は組織的施策で実現可能
2. **因果的根拠**: 行動変化が継続に与える影響を学習
3. **持続可能性**: 個人依存ではなく組織的な仕組み
4. **予防的**: 離脱の原因（活動間隔、負荷）に事前対処

一方，RFの「応答速度」は個人特性で変更しにくく，実務的な施策に落とし込むことが困難である．

## 6.7 本研究の限界と今後の課題

### 6.7.1 単一プロジェクトによる制約

本研究はOpenStack/Nova単一プロジェクトを対象としており，他のプロジェクト（GitHub利用など）では異なる結果が得られる可能性がある．今後，複数プロジェクトでの検証が必要である．

### 6.7.2 特徴量の網羅性

本研究で用いた14の特徴量（状態10+行動4）がレビュアー継続の全要因を捉えているわけではない．特にタスクの専門性の一致度など，未考慮の要因が存在する可能性がある．

### 6.7.3 因果推論の限界

IRLの勾配値は「因果的影響の近似」であり，真の因果関係を保証するものではない．より厳密な因果推論には，介入実験や傾向スコアマッチングなどの手法が必要である．

## 6.8 考察のまとめ

本章では，以下の重要な発見を考察した：

1. **時系列学習の有効性**: LSTMによる時系列考慮がAUC-ROC 0.820を実現
2. **短期 vs 長期の特徴変化**: 活動量→質的要因への重要度シフト
3. **RFとIRLの本質的違い**: 静的相関 vs 動的因果，最大12ランクの逆転
4. **実務的含意**: IRLの因果ベース施策が介入可能性で優位

特に，**RQ4で明らかになったモデル間の劇的な順位逆転は，特徴量重要度の解釈がモデル選択に強く依存することを示し**，ソフトウェア工学研究における特徴量分析の方法論に重要な示唆を与える．