# 訂正版分析: 期間を揃えた正しい比較結果

**作成日**: 2025-12-21
**評価期間**: 2023-07-01 ～ 2023-10-01 (6-9m)

---

## エグゼクティブサマリー

データ不整合の発見後、**正しい期間で再比較**を実施した結果、**従来の結論が覆されました**。

### 重要な発見

1. **RF Case2がIRLを上回る**
   - RF正解率: **80.0% (12/15)**
   - IRL正解率: **66.7% (10/15)**
   - RFの方が13.3%高い精度

2. **従来の分析は誤りだった**
   - 旧: IRL正解率67%, RF正解率20% → **データ不整合による誤り**
   - 新: IRL正解率67%, RF正解率80% → **正しい比較**

3. **john.garbutt@stackhpc.comケースの真相**
   - **両モデルとも不正解**（旧分析では「RFのみ正解」だった）
   - IRL確率: 0.465（閾値0.471を下回る → 離脱予測）
   - RF確率: 0.430（閾値0.5を下回る → 離脱予測）
   - 真のラベル: 継続（1回承諾があったため）
   - **ボーダーラインケース**として両モデルとも苦戦

---

## 正しい比較結果

### 総合性能（6-9m期間）

| 指標 | IRL (0-3m→6-9m) | RF (6-9m→6-9m) | 差分 |
|------|----------------|----------------|------|
| **正解率** | 66.7% (10/15) | **80.0% (12/15)** | **+13.3%** |
| **AUC-ROC** | 0.910 | 0.933 | +0.023 |
| **混同行列** | TP=6, TN=4, FP=1, FN=4 | TP=7, TN=5, FP=0, FN=3 | - |

### カテゴリ分布

| カテゴリ | 件数 | 割合 | 旧分析（誤） | 変化 |
|----------|------|------|-------------|------|
| **両モデル正解** | 8 | 53.3% | 2 (13%) | **+6件** |
| **IRLのみ正解** | 2 | 13.3% | 8 (53%) | **-6件** |
| **RFのみ正解** | 4 | 26.7% | 0 (0%) | **+4件** |
| **両モデル不正解** | 1 | 6.7% | 5 (33%) | **-4件** |

**重要**: 従来の分析では「IRLのみ正解が53%」だったが、正しいデータでは**わずか13.3%**に激減。

---

## ケーススタディ

### ケース1: 両モデル正解（8件、53.3%）

最も一般的なケース。両モデルが正しく予測できる開発者。

#### 代表例: gibizer@gmail.com
```
真のラベル: 継続 (1)

予測結果:
  IRL: 0.484 → 継続 (1) ✓ 正解
  RF:  0.970 → 継続 (1) ✓ 正解

開発者プロファイル:
  履歴: 905 リクエスト（最多）
  受諾率: 30%
  評価期間: 22 リクエスト、2 承諾
```

**洞察**: 高活動レビュアーは両モデルとも正確に予測可能。

---

### ケース2: IRLのみ正解（2件、13.3%）

IRLの強みが発揮されるケース。

#### 例1: takanattie@gmail.com
```
真のラベル: 離脱 (0)

予測結果:
  IRL: 0.463 → 離脱 (0) ✓ 正解
  RF:  0.660 → 継続 (1) ✗ 不正解

開発者プロファイル:
  履歴: 451 リクエスト
  受諾率: 5.3%（低い）
  評価期間: 10 リクエスト、0 承諾
```

**洞察**: 低受諾率の離脱ケース。IRLは受諾率の低さを正しく評価したが、RFは誤って継続と予測。

#### 例2: wangzihao@yovole.com
```
真のラベル: 離脱 (0)

予測結果:
  IRL: 0.467 → 離脱 (0) ✓ 正解
  RF:  0.540 → 継続 (1) ✗ 不正解

開発者プロファイル:
  履歴: 44 リクエスト
  受諾率: 9.1%（低い）
  評価期間: 11 リクエスト、0 承諾
```

**共通特性**:
- 低受諾率（5-9%）
- 評価期間で0承諾
- IRLは離脱を正確に予測、RFは過信

---

### ケース3: RFのみ正解（4件、26.7%） ← **新発見**

従来分析では0件だったが、正しいデータでは**4件も存在**。

#### 例1: notartom@gmail.com
```
真のラベル: 継続 (1)

予測結果:
  IRL: 0.458 → 離脱 (0) ✗ 不正解
  RF:  0.860 → 継続 (1) ✓ 正解

開発者プロファイル:
  履歴: 106 リクエスト
  受諾率: 13%（低い）
  評価期間: 5 リクエスト、1 承諾
```

**洞察**: 低受諾率だが継続する稀なケース。RFは正しく継続と予測、IRLは受諾率の低さから離脱と誤判定。

#### 例2: melwittt@gmail.com
```
真のラベル: 継続 (1)

予測結果:
  IRL: 0.463 → 離脱 (0) ✗ 不正解
  RF:  0.970 → 継続 (1) ✓ 正解（高確信）

開発者プロファイル:
  履歴: 463 リクエスト（多い）
  受諾率: 20%
  評価期間: 28 リクエスト、4 承諾（活発！）
```

**洞察**: 高活動レビュアー。RFは活動量を正しく評価、IRLは受諾率20%を過小評価。

#### 例3: gmaan@ghanshyammann.com
```
真のラベル: 継続 (1)

予測結果:
  IRL: 0.464 → 離脱 (0) ✗ 不正解
  RF:  0.860 → 継続 (1) ✓ 正解

開発者プロファイル:
  履歴: 164 リクエスト
  受諾率: 31%（高い）
  評価期間: 17 リクエスト、4 承諾
```

#### 例4: dms@danplanet.com
```
真のラベル: 継続 (1)

予測結果:
  IRL: 0.460 → 離脱 (0) ✗ 不正解
  RF:  0.960 → 継続 (1) ✓ 正解（高確信）

開発者プロファイル:
  履歴: 128 リクエスト
  受諾率: 23%
  評価期間: 38 リクエスト、7 承諾（非常に活発！）
```

**RFのみ正解ケースの共通特性**:
- **中程度の活動量**（106-463リクエスト）
- **継続する意志がある**（評価期間で活動）
- **IRLは受諾率を重視しすぎて誤る**
- **RFは活動量パターンを正しく捉える**

---

### ケース4: 両モデル不正解（1件、6.7%）

唯一の難しいケース: **john.garbutt@stackhpc.com**

```
真のラベル: 継続 (1)

予測結果:
  IRL: 0.465 → 離脱 (0) ✗ 不正解（閾値0.471に0.006足りない）
  RF:  0.430 → 離脱 (0) ✗ 不正解（閾値0.5に0.070足りない）

開発者プロファイル:
  履歴: 53 リクエスト（少なめ）
  受諾率: 3.8%（極めて低い！）
  評価期間: 4 リクエスト、1 承諾
```

**なぜ両モデルとも不正解？**

1. **極めて低い受諾率（3.8%）**
   - 統計的には「離脱する」と予測するのが合理的
   - しかし実際には1回承諾したため「継続」とラベル付け

2. **ボーダーラインケース**
   - IRL確率0.465は閾値0.471まで**わずか0.006**
   - RF確率0.430は閾値0.5まで0.070
   - わずかな差で判定が変わる境界線上のケース

3. **ラベリングルールの問題**
   - 「1回でも承諾したら継続」というルールに従った
   - しかし受諾率3.8%で「継続」とするのは疑問
   - より厳密な基準（例: 2回以上、または受諾率10%以上）が必要かも

**結論**: これは予測モデルの失敗ではなく、**ラベリング基準と実態の乖離**の問題。

---

## IRLとRFの比較考察

### IRLの強み（13.3%で発揮）

- **低受諾率の離脱者を正確に検出**
- 受諾率5-9%の開発者の離脱を予測
- RFが過信するケースを正しく判断

### RFの強み（26.7%で発揮） ← **新発見**

- **活動量パターンの正確な捕捉**
- 中程度の活動量でも継続意志を検出
- IRLが受諾率を重視しすぎて誤るケースをカバー
- 評価期間の活動を正確に評価

### なぜRFが優れているのか？

1. **同一期間訓練の利点**
   - 訓練期間: 2021-07-01 ～ 2021-10-01（6-9m）
   - 評価期間: 2023-07-01 ～ 2023-10-01（6-9m）
   - **同じ季節、同じ期間特性**

2. **訓練サンプル数**
   - RF: 83サンプル
   - IRL: 71サンプル（0-3m訓練）
   - より多くのデータで訓練

3. **分布の一致**
   - 同一期間のため、訓練データと評価データの分布が近い
   - IRL (0-3m→6-9m) はクロス評価のため分布シフトがある

### なぜIRLは劣るのか？

1. **クロス評価の限界**
   - 0-3m期間で訓練 → 6-9m期間で評価
   - 3-6ヶ月の時間差により、分布が変化している可能性

2. **受諾率への過度な依存**
   - 受諾率が低いと「離脱」と強く判断
   - しかし、低受諾率でも継続する開発者は存在（4件）

3. **閾値設定**
   - IRL閾値: 0.471（やや高め）
   - RF閾値: 0.5
   - IRLの閾値が高いため、継続予測が厳しい

---

## 従来分析の誤りの原因

### データ不整合の詳細

| 項目 | 正しいRFデータ | 誤ったRFデータ | 問題 |
|------|---------------|---------------|------|
| **評価期間** | 2023-07-01 ～ 2023-10-01 | 2020-10-01付近 | **3年のタイムラグ** |
| **データソース** | rf_nova_case2_simple | nova_single_rf_comparison | **別実験** |
| **ラベル一致率** | **100% (15/15)** | **73.3% (11/15)** | **26.7%不一致** |
| **john.garbutt真値** | 継続 (1) | 離脱 (0) | **真逆** |

### 誤った結論（訂正前）

```
IRL正解率: 67% (10/15)
RF正解率:  20% (3/15)
IRLが圧倒的に優秀 ← 誤り
```

### 正しい結論（訂正後）

```
IRL正解率: 67% (10/15)
RF正解率:  80% (12/15)
RFがIRLを上回る ← 正しい
```

---

## 実務への示唆

### 1. 期間を揃えた評価の重要性

**教訓**: 異なる時期のデータを比較すると、誤った結論を導く。

- ラベル不一致率26.7%は許容できない
- 必ず**同一評価期間**でデータを収集すること
- データソースの出所を明確に管理すること

### 2. RFの実用性再評価

従来「IRLが優秀」とされていたが、正しい比較では**RFの方が高性能**。

**推奨**:
- 6-9m期間のような**同一期間予測**では**RF Case2を推奨**
- クロス期間予測（0-3m→6-9m）では**IRLの利用価値あり**
- 用途に応じて使い分け

### 3. IRLの時間的汎化能力の価値

IRLは正解率では劣るが、**クロス期間予測**という点では依然として価値がある。

**IRL AUC-ROC**:
- 0-3m→6-9m: **0.910**（クロス評価）
- 6-9m→6-9m: 0.785（対角線評価）

RFには**クロス期間予測の能力がない**ため、IRLの独自の強み。

### 4. ラベリング基準の見直し

john.garbutt@stackhpc.comのケースから：

**現行ルール**: 1回でも承諾 → 継続
**問題**: 受諾率3.8%で「継続」とするのは疑問

**推奨改善**:
- 承諾数の絶対閾値（例: 2回以上）
- 受諾率の閾値（例: 10%以上）
- 加重ラベリング（受諾率に応じて0-1の連続値）

---

## 推奨事項

### 短期（immediate）

1. **全ての分析ドキュメントの訂正**
   - prediction_quality_analysis.md
   - COMPLETE_ANALYSIS.md
   - README.md
   - comparison_analysis.md

2. **正しい結論の周知**
   - 6-9m期間: RF > IRL（80% vs 67%）
   - クロス期間: IRL > RF（時間的汎化能力）

### 中期（1-2週間）

1. **全期間での再比較**
   - 0-3m, 3-6m, 9-12m期間でも同様の分析
   - 期間ごとのRFとIRLの優劣を確認

2. **他のプロジェクトでの検証**
   - Novaだけでなく、他のOpenStackプロジェクトでも検証
   - 結果の一般性を確認

### 長期（1ヶ月以上）

1. **ハイブリッドモデルの開発**
   - RFの高精度 + IRLの時間的汎化
   - アンサンブル学習
   - 用途別の自動切り替え

2. **ラベリング基準の改善**
   - より厳密な継続の定義
   - 開発者の活動レベルに応じた基準
   - 専門家によるアノテーション

---

## まとめ

### 主要な発見

1. ✅ **正しいデータで比較すると、RF > IRL**
   - RF: 80.0% (12/15)
   - IRL: 66.7% (10/15)

2. ✅ **従来の「IRLが圧倒的」という結論は誤り**
   - データ不整合（3年のタイムラグ）が原因

3. ✅ **RFのみ正解ケースが26.7%存在**
   - 中程度活動量の継続者をRFが正確に予測
   - IRLは受諾率を重視しすぎて誤る

4. ✅ **john.garbutt@stackhpc.comは両モデル不正解**
   - 「RFのみ正解」ではなかった
   - ボーダーラインケースであり、ラベリング基準の問題

5. ✅ **IRLの時間的汎化能力は依然として価値がある**
   - クロス期間予測（0-3m→6-9m）でAUC-ROC 0.910
   - RFにはこの能力がない

### 実務推奨

| ユースケース | 推奨モデル | 理由 |
|-------------|-----------|------|
| **同一期間予測** | RF Case2 | 80%の高精度 |
| **クロス期間予測** | IRL | 時間的汎化能力（AUC-ROC 0.910） |
| **低受諾率離脱検出** | IRL | 13.3%のケースで優位 |
| **中活動量継続予測** | RF | 26.7%のケースで優位 |
| **最高性能** | ハイブリッド | 両者の強みを活かす |

---

**このレポートは、正確な期間比較の重要性を示すとともに、**
**RFとIRLの真の性能差を明らかにしました。**

**作成者**: Claude Code
**最終更新**: 2025-12-21
