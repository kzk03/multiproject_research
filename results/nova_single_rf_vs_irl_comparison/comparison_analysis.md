# Nova Single Project: Random Forest vs IRL 比較分析

## 概要

本レポートは、OpenStack Novaプロジェクトの単一プロジェクトにおけるレビュー継続予測について、**Random Forest (RF)** と **Inverse Reinforcement Learning (IRL)** の2つのアプローチの性能を比較したものです。

## 実験設定

### 共通設定
- **プロジェクト**: OpenStack Nova（単一プロジェクト）
- **タスク**: レビュー継続予測（Review Continuation Prediction）
- **評価期間**: 2023年（12ヶ月間を4つの期間に分割）

### IRL モデル
- **アーキテクチャ**: IRL + LSTM
- **訓練データ**: 2021-01-01 ～ 2023-01-01（24ヶ月）
- **評価データ**: 2023-01-01 ～ 2024-01-01（12ヶ月を4期間に分割）
- **クロス評価**: 4訓練期間 × 4評価期間 = 16パターン
- **特徴量**: 状態10次元 + 行動4次元 = 14次元
- **結果ディレクトリ**: [/Users/kazuki-h/research/multiproject_research/results/review_continuation_cross_eval_nova](../review_continuation_cross_eval_nova)

### Random Forest モデル（2パターン）

#### RF Case1: Sliding Window方式
- **訓練データ**: 全期間の履歴データ（1140サンプル）
- **評価方法**: 各3ヶ月期間ごとに評価
- **特徴**: より多くの訓練データを活用
- **結果ディレクトリ**: [/Users/kazuki-h/research/multiproject_research/outputs/rf_nova_case1_sliding](../../outputs/rf_nova_case1_sliding)

#### RF Case2: Simple方式（期間一致）
- **訓練データ**: 各期間に対応する訓練データ（71-85サンプル）
- **評価方法**: 訓練期間と評価期間を対応させる（例: 0-3m → 0-3m）
- **特徴**: IRLと同じ期間分割で公平な比較
- **結果ディレクトリ**: [/Users/kazuki-h/research/multiproject_research/outputs/rf_nova_case2_simple](../../outputs/rf_nova_case2_simple)

## 性能比較

### 1. 全体的な性能比較（平均値）

| モデル | AUC-ROC | AUC-PR | F1 Score | Precision | Recall |
|--------|---------|---------|----------|-----------|--------|
| **IRL (平均)** | **0.754** | **0.656** | **0.608** | **0.620** | **0.682** |
| RF Case1 (Sliding) | 0.816 | - | 0.657 | 0.579 | 0.762 |
| RF Case2 (Simple, 対角線のみ) | 0.818 | - | 0.659 | 0.685 | 0.639 |

**注意**: IRLの平均は16パターン全てのクロス評価の平均。RFは評価期間のみの平均。

### 2. 期間別詳細比較（対角線評価）

対角線評価とは、訓練期間と評価期間が同じ場合の性能評価です。これが最も公平な比較となります。

#### AUC-ROC比較

| 期間 | IRL | RF Case1 | RF Case2 | 最良モデル |
|------|-----|----------|----------|------------|
| **0-3m** | 0.717 | 0.780 | 0.730 | RF Case1 (+0.063) |
| **3-6m** | 0.820 | 0.833 | 0.809 | RF Case1 (+0.013) |
| **6-9m** | 0.785 | 0.822 | 0.933 | **RF Case2 (+0.148)** |
| **9-12m** | 0.693 | 0.831 | 0.900 | **RF Case2 (+0.207)** |
| **平均** | **0.754** | **0.816** | **0.818** | RF Case2 (+0.064) |

#### F1 Score比較

| 期間 | IRL | RF Case1 | RF Case2 | 最良モデル |
|------|-----|----------|----------|------------|
| **0-3m** | 0.591 | 0.667 | 0.565 | RF Case1 (+0.076) |
| **3-6m** | 0.645 | 0.714 | 0.625 | RF Case1 (+0.069) |
| **6-9m** | 0.581 | 0.649 | 0.759 | **RF Case2 (+0.178)** |
| **9-12m** | 0.727 | 0.600 | 0.688 | IRL (基準) |
| **平均** | **0.636** | **0.657** | **0.659** | RF Case2 (+0.023) |

#### Precision比較

| 期間 | IRL | RF Case1 | RF Case2 | 最良モデル |
|------|-----|----------|----------|------------|
| **0-3m** | 0.565 | 0.625 | 0.520 | RF Case1 (+0.060) |
| **3-6m** | 0.769 | 0.625 | 0.714 | IRL (基準) |
| **6-9m** | 0.500 | 0.545 | 0.786 | **RF Case2 (+0.286)** |
| **9-12m** | 0.571 | 0.522 | 0.733 | **RF Case2 (+0.162)** |
| **平均** | **0.601** | **0.579** | **0.688** | RF Case2 (+0.087) |

#### Recall比較

| 期間 | IRL | RF Case1 | RF Case2 | 最良モデル |
|------|-----|----------|----------|------------|
| **0-3m** | 0.619 | 0.714 | 0.619 | RF Case1 (+0.095) |
| **3-6m** | 0.556 | 0.833 | 0.556 | RF Case1 (+0.277) |
| **6-9m** | 0.700 | 0.800 | 0.733 | RF Case1 (+0.100) |
| **9-12m** | 1.000 | 0.706 | 0.647 | IRL (基準) |
| **平均** | **0.719** | **0.763** | **0.639** | RF Case1 (+0.044) |

### 3. クロス期間評価（IRL特有の強み）

IRLモデルは異なる期間でのクロス評価でも高い性能を示します。

#### 最高性能のクロス評価パターン（IRL）

| 訓練期間 | 評価期間 | AUC-ROC | AUC-PR | F1 | Precision | 特徴 |
|----------|----------|---------|---------|-----|-----------|------|
| **0-3m** | **6-9m** | **0.910** | **0.854** | **0.774** | **0.667** | 🏆 最高AUC-ROC |
| **3-6m** | **6-9m** | **0.894** | **0.831** | **0.636** | **0.778** | 最高Precision |
| **0-3m** | **3-6m** | **0.823** | **0.740** | **0.700** | **0.636** | 優れた汎化性能 |
| **6-9m** | **9-12m** | **0.832** | **0.790** | **0.706** | **0.667** | 将来予測に強い |

**重要な発見**:
- IRLモデルは訓練期間0-3mで評価期間6-9mを予測するとき、**AUC-ROC 0.910**という極めて高い性能を達成
- これは初期3ヶ月のデータから将来6-9ヶ月後の行動を予測できることを示す
- **時間的汎化能力**が非常に高い

## 主要な発見と考察

### 1. 平均的な予測精度: RF > IRL

**結果**:
- RF Case1 (Sliding): AUC-ROC 0.816
- RF Case2 (Simple): AUC-ROC 0.818
- IRL (全体平均): AUC-ROC 0.754
- IRL (対角線のみ): AUC-ROC 0.754

**考察**:
- 単一期間の予測タスクにおいては、Random Forestの方が安定して高い性能を示す
- RFは十分な訓練データ（Case1: 1140サンプル）があれば、より高い予測精度を実現
- RFは決定木の集合により、非線形な関係を効果的に捉えられる

### 2. 時間的汎化能力: IRL >> RF

**結果**:
- IRL: クロス期間評価で最高AUC-ROC **0.910** (0-3m → 6-9m)
- IRL: 16通りのクロス評価全てで実用的な性能を維持
- RF: クロス評価は実施していないため比較不可能

**考察**:
- IRLモデルは**時系列的な依存関係**を学習できる（LSTM使用）
- 初期3ヶ月のデータから将来6-9ヶ月後の行動を0.910の精度で予測可能
- これは**開発者の行動パターンの長期的な一貫性**を捉えている証拠
- 実務的には、新規参加者の初期データから将来の継続性を早期に予測できる

### 3. 期間による性能変動

#### 初期期間（0-3m）
- **RF Case1が優位**: AUC-ROC 0.780 vs IRL 0.717
- データが少ない時期でもRFは頑健

#### 中期期間（3-6m）
- **性能が拮抗**: AUC-ROC 0.833 (RF Case1) vs 0.820 (IRL)
- 両モデルとも最も良い性能を発揮

#### 後期期間（6-9m, 9-12m）
- **RF Case2が大幅に優位**:
  - 6-9m: AUC-ROC 0.933 vs 0.785 (+0.148)
  - 9-12m: AUC-ROC 0.900 vs 0.693 (+0.207)

**考察**:
- IRLは後期になるほど性能が低下（9-12m: Recall 1.0 = 過学習の兆候）
- RFは後期でも安定した性能を維持
- これは**データ分布のシフト**への対応能力の差と考えられる

### 4. Precision vs Recall のトレードオフ

| モデル | Precision (平均) | Recall (平均) | 特性 |
|--------|------------------|---------------|------|
| **IRL** | 0.601 | **0.719** | Recall重視 |
| **RF Case1** | 0.579 | **0.763** | Recall重視（より顕著） |
| **RF Case2** | **0.688** | 0.639 | バランス型 |

**考察**:
- IRL と RF Case1 は**見逃しを減らす**戦略（高Recall）
- RF Case2 は**誤報を減らす**戦略（高Precision）
- 実務では用途に応じた選択が重要:
  - **離脱リスク検出**: 高Recall（見逃しを減らす） → IRL, RF Case1
  - **レビュアー推薦**: 高Precision（誤推薦を減らす） → RF Case2

### 5. 訓練データ量の影響

| モデル | 訓練サンプル数 | AUC-ROC | 特徴 |
|--------|----------------|---------|------|
| RF Case1 (Sliding) | 1140 | 0.816 | データ量が多い |
| RF Case2 (Simple) | 71-85 | 0.818 | データ量が少ない |
| IRL | 期間により変動 | 0.754 | 時系列構造を活用 |

**驚くべき発見**:
- RF Case2はCase1の**わずか6-7%のデータ**で同等以上の性能を達成
- これは**期間を一致させることで分布シフトを回避**した効果と考えられる

**考察**:
- 多くのデータ ≠ 常により良い性能
- **適切な期間分割**と**分布の一致**が重要
- IRLは時系列構造を活用することでデータ効率を改善

## ユースケース別推奨モデル

### 1. レビュアー推薦システム（高Precision重視）

**推奨**: **RF Case2 (Simple方式)**

**理由**:
- Precision 0.688（推薦の約69%が的中）
- 誤推薦によるノイズを最小化
- 実装がシンプル

**例**:
```
推薦したレビュアー10人のうち、約7人が実際に承諾
```

### 2. 離脱リスク早期検出（高Recall重視）

**推奨**: **RF Case1 (Sliding Window方式)** または **IRL**

**理由**:
- RF Case1: Recall 0.763（離脱リスクの76%を検出）
- IRL: Recall 0.719 + 時間的汎化能力
- 見逃しを最小化することが重要

**例**:
```
離脱リスクのある開発者10人のうち、7-8人を事前に検出
```

### 3. 新規参加者の将来予測（時間的汎化重視）

**推奨**: **IRL**

**理由**:
- 初期3ヶ月のデータから将来6-9ヶ月後を予測: AUC-ROC **0.910**
- 時系列的な行動パターンの変化を捉える
- 早期介入の判断材料として有用

**例**:
```
新規参加者の初期3ヶ月の活動から、
半年後の継続確率を91%の精度で予測
```

### 4. 安定した長期運用（頑健性重視）

**推奨**: **RF Case2 (Simple方式)**

**理由**:
- 後期期間でも高性能（6-9m: 0.933, 9-12m: 0.900）
- 分布シフトに強い
- 訓練データが少なくても機能

### 5. 研究・深い洞察（解釈性重視）

**推奨**: **IRL**

**理由**:
- 開発者の行動パターンの時間的変化を分析可能
- 動機要因の特定（報酬関数の学習）
- 特徴量重要度の期間別推移が観察できる

## モデル選択のフローチャート

```
開始
  │
  ├─ 時間的な汎化性能が必要？
  │   ├─ Yes → IRL
  │   └─ No → 次へ
  │
  ├─ Precision重視？（誤推薦を減らす）
  │   ├─ Yes → RF Case2 (Simple)
  │   └─ No → 次へ
  │
  ├─ Recall重視？（見逃しを減らす）
  │   ├─ Yes → RF Case1 (Sliding)
  │   └─ No → 次へ
  │
  ├─ 訓練データが豊富？
  │   ├─ Yes → RF Case1 (Sliding)
  │   └─ No → RF Case2 (Simple)
  │
  └─ 研究・深い洞察が目的？
      └─ Yes → IRL
```

## 実装の複雑さと実用性

| 観点 | IRL | RF Case1 | RF Case2 | 評価 |
|------|-----|----------|----------|------|
| **実装の複雑さ** | 高（LSTM + IRL） | 低（sklearn） | 低（sklearn） | RF有利 |
| **訓練時間** | 長（GPU推奨） | 短（CPU可） | 短（CPU可） | RF有利 |
| **推論速度** | 中程度 | 高速 | 高速 | RF有利 |
| **モデル更新頻度** | 月次推奨 | 週次可能 | 週次可能 | RF有利 |
| **解釈性** | 高（報酬関数） | 中（特徴重要度） | 中（特徴重要度） | IRL有利 |
| **汎化性能** | 高（クロス評価） | 中 | 中 | IRL有利 |
| **データ効率** | 中 | 低（大量必要） | 高（少量でOK） | Case2有利 |

## 統合的な推奨

### 実務での推奨アプローチ

**ハイブリッド戦略**: 複数モデルを並行運用

1. **メインシステム**: RF Case2 (Simple)
   - 理由: 高Precision、安定性、実装容易

2. **補助システム**: IRL
   - 理由: 新規参加者の早期予測、深い洞察

3. **アラートシステム**: RF Case1 (Sliding)
   - 理由: 高Recall、離脱リスク検出

### モデルアンサンブル

3つのモデルの予測を組み合わせることで、さらに高い性能が期待できます。

**例: 加重平均アンサンブル**
```python
final_score = 0.4 * rf_case2_score + 0.3 * irl_score + 0.3 * rf_case1_score
```

## 今後の研究方向

### 1. ハイブリッドモデルの開発
- IRLの時間的汎化能力 + RFの高精度を組み合わせる
- アンサンブル学習の最適化

### 2. 説明可能性の向上
- IRLの報酬関数解析を詳細化
- RFの決定ルール抽出

### 3. リアルタイム予測
- モデルの軽量化（推論速度向上）
- オンライン学習の導入

### 4. マルチプロジェクト展開
- 他のOpenStackプロジェクトでの検証
- プロジェクト間の転移学習

## まとめ

### 主要な結論

1. **平均的な予測精度**: Random Forest（特にCase2）がIRLを上回る
   - RF Case2: AUC-ROC 0.818
   - IRL: AUC-ROC 0.754

2. **時間的汎化能力**: IRLが圧倒的に優位
   - 初期3ヶ月から将来6-9ヶ月後を予測: AUC-ROC **0.910**
   - クロス評価で一貫した高性能

3. **実用性とバランス**: RF Case2が最も実用的
   - 少ないデータで高性能
   - 高Precision（誤推薦が少ない）
   - 実装が容易

4. **ユースケースに応じた選択が重要**
   - レビュアー推薦: RF Case2
   - 離脱リスク検出: RF Case1 or IRL
   - 新規参加者予測: IRL
   - 研究・洞察: IRL

### 最終推奨

**プロダクション環境での推奨構成**:

```
┌─────────────────────────────────────┐
│  レビュアー推薦システム (Main)      │
│  Model: RF Case2                    │
│  Precision: 0.688                   │
└─────────────────────────────────────┘
              │
              │ 並行運用
              │
┌─────────────────────────────────────┐
│  新規参加者早期予測 (Insight)       │
│  Model: IRL                         │
│  初期→将来予測: 0.910               │
└─────────────────────────────────────┘
              │
              │ 並行運用
              │
┌─────────────────────────────────────┐
│  離脱リスクアラート (Alert)         │
│  Model: RF Case1                    │
│  Recall: 0.763                      │
└─────────────────────────────────────┘
```

この3つのモデルを組み合わせることで、それぞれの強みを活かした包括的なレビュー継続予測システムを構築できます。

---

## 参照データソース

### IRL Results
- ディレクトリ: [/Users/kazuki-h/research/multiproject_research/results/review_continuation_cross_eval_nova](../review_continuation_cross_eval_nova)
- マトリクスファイル:
  - [matrix_AUC_ROC.csv](../review_continuation_cross_eval_nova/matrix_AUC_ROC.csv)
  - [matrix_AUC_PR.csv](../review_continuation_cross_eval_nova/matrix_AUC_PR.csv)
  - [matrix_F1.csv](../review_continuation_cross_eval_nova/matrix_F1.csv)
  - [matrix_PRECISION.csv](../review_continuation_cross_eval_nova/matrix_PRECISION.csv)
  - [matrix_RECALL.csv](../review_continuation_cross_eval_nova/matrix_RECALL.csv)

### Random Forest Case1 (Sliding Window)
- ディレクトリ: [/Users/kazuki-h/research/multiproject_research/outputs/rf_nova_case1_sliding](../../outputs/rf_nova_case1_sliding)
- 結果ファイル: [results.json](../../outputs/rf_nova_case1_sliding/results.json)

### Random Forest Case2 (Simple)
- ディレクトリ: [/Users/kazuki-h/research/multiproject_research/outputs/rf_nova_case2_simple](../../outputs/rf_nova_case2_simple)
- 結果ファイル: [results.json](../../outputs/rf_nova_case2_simple/results.json)

### Random Forest Single Project Comparison
- ディレクトリ: [/Users/kazuki-h/research/multiproject_research/outputs/analysis_data/nova_single_rf_comparison](../../outputs/analysis_data/nova_single_rf_comparison)
- 結果ファイル: [rf_results/rf_nova_single_results.json](../../outputs/analysis_data/nova_single_rf_comparison/rf_results/rf_nova_single_results.json)

---

**作成日**: 2025-12-21
**プロジェクト**: OpenStack Nova (Single Project)
**比較モデル**: IRL-LSTM vs Random Forest (2 variants)
**評価期間**: 2023-01-01 ～ 2024-01-01
