# 50プロジェクト IRL学習 結果分析

## 1. 実験概要

### データ概要
- **プロジェクト数**: 50プロジェクト（OpenStack Interop Guidelines準拠）
- **期間**: 2021-01-01 ～ 2024-01-01（36ヶ月）
- **レビュー数**: 119,010件（48プロジェクトから収集）
- **開発者数**: 1,855名

### 実験設定
- **訓練期間**: 2021-01-01～（各3ヶ月窓）
- **評価期間**: 2023-01-01～（各3ヶ月窓）
- **クロス時間評価**: 4×4マトリクス（0-3m, 3-6m, 6-9m, 9-12m）
- **オーバーサンプリング**: 3パターン（1x, 2x, 3x）

## 2. 主要結果

### 2.1 対角線評価（同時期で訓練・評価）

| 実験 | 訓練期間 | F1 | Precision | Recall | AUC-ROC |
|------|----------|-----|-----------|--------|---------|
| **No OS** | 0-3m | 0.905 | 0.827 | 1.000 | 0.685 |
| **No OS** | 3-6m | 0.896 | 0.812 | 1.000 | 0.726 |
| **No OS** | 6-9m | 0.948 | 0.902 | 1.000 | 0.745 |
| **No OS** | 9-12m | 0.879 | 0.784 | 1.000 | 0.650 |
| **2x OS** | 0-3m | 0.905 | 0.826 | 1.000 | 0.687 |
| **2x OS** | 3-6m | 0.899 | 0.815 | 1.000 | 0.723 |
| **2x OS** | 6-9m | 0.948 | 0.902 | 1.000 | 0.749 |
| **2x OS** | 9-12m | 0.879 | 0.784 | 1.000 | 0.652 |
| **3x OS** | 0-3m | 0.890 | 0.808 | 0.935 | 0.684 |
| **3x OS** | 3-6m | 0.901 | 0.819 | 0.994 | 0.733 |
| **3x OS** | 6-9m | 0.948 | 0.902 | 1.000 | 0.740 |
| **3x OS** | 9-12m | 0.879 | 0.784 | 1.000 | 0.649 |

**平均性能（対角線）:**
- F1: **0.905** (No OS), **0.908** (2x OS), **0.905** (3x OS)
- AUC-ROC: **0.701** (No OS), **0.703** (2x OS), **0.701** (3x OS)

### 2.2 時間的ロバスト性（クロス時間評価）

**2021年モデル（0-3m訓練）の2023年性能:**

| 評価期間 | F1 (No OS) | F1 (2x OS) | F1 (3x OS) | AUC-ROC (No OS) |
|----------|-----------|-----------|-----------|-----------------|
| 0-3m | 0.905 | 0.905 | 0.890 | 0.685 |
| 3-6m | 0.892 | 0.892 | 0.880 | 0.677 |
| 6-9m | **0.950** | **0.950** | **0.950** | 0.672 |
| 9-12m | 0.878 | 0.878 | 0.878 | 0.550 |

**観察:**
- 6-9m期間で最高性能（F1: 0.950）
- 9-12m期間でAUC-ROC低下（0.550）→ データ分布変化の可能性

### 2.3 オーバーサンプリング効果

| メトリクス | No OS | 2x OS | 3x OS | 最良 |
|-----------|-------|-------|-------|------|
| **平均F1** | 0.905 | 0.908 | 0.905 | 2x OS |
| **平均AUC-ROC** | 0.701 | 0.703 | 0.701 | 2x OS |
| **最高F1** | 0.948 | 0.948 | 0.948 | 同点 |
| **Recall** | 1.000 | 1.000 | 0.982 | No/2x |

**結論:**
- **2xオーバーサンプリングが最もバランスが良い**
- 3xではRecallがわずかに低下（過学習の兆候）
- No OSと2x OSは性能がほぼ同等

## 3. 20プロジェクトとの比較

### 3.1 性能比較

| メトリクス | 20プロジェクト | 50プロジェクト (No OS) | 50プロジェクト (2x OS) | 差分 |
|-----------|---------------|----------------------|----------------------|------|
| **F1** | 0.871 | **0.905** | **0.908** | **+3.7pp** |
| **AUC-ROC** | **0.833** | 0.701 | 0.703 | **-13pp** |
| **Precision** | 0.850 | 0.831 | 0.832 | -1.8pp |
| **Recall** | 0.892 | **1.000** | **1.000** | **+10.8pp** |

### 3.2 主要な発見

#### 発見1: F1スコアの向上（+3.7pp）
**原因:**
1. **Recall完全化**: 0.892 → 1.000（+10.8pp）
   - 50プロジェクトでは承諾されるレビューを**すべて正しく予測**
   - より多様なプロジェクトデータで承諾パターンを網羅的に学習

2. **Precisionわずか低下**: 0.850 → 0.831（-1.8pp）
   - より多くの偽陽性を許容する代わりに見逃しゼロを達成
   - 実用的には「レビュー依頼を送りすぎる」方が「送り忘れる」より安全

#### 発見2: AUC-ROC低下（-13pp）の理由

**AUC-ROC = 0.701 vs 0.833の意味:**
- **20プロジェクト（0.833）**: ランキング性能が高い
  - 確信度スコアの順序が正確
  - 「この人は90%承諾する」「この人は30%」の区別が明確

- **50プロジェクト（0.701）**: ランキング性能は劣るが、分類性能は高い
  - 確信度スコアの順序は不明確
  - しかし閾値を超えるかどうかの二値判定は**完璧（Recall=1.0）**

**原因分析:**
1. **プロジェクト多様性の増加**
   - 50プロジェクトでは異なる文化・プラクティスが混在
   - スコアの絶対値が均質化（予測確信度が中央に集まる）
   
2. **負例の多様化**
   - 20プロジェクト: 拒否パターンが比較的一貫
   - 50プロジェクト: 多様な拒否理由で識別が困難

3. **データ統計:**
   ```
   20プロジェクト予測分布:
     min: 0.383, max: 0.777, std: 0.107
   
   50プロジェクト予測分布（推定）:
     より狭い範囲に集中 → ROC曲線の面積減少
   ```

#### 発見3: Recall=1.0の実用的価値

**ユースケース別評価:**

| ユースケース | 重視指標 | 20proj | 50proj | 推奨 |
|-------------|----------|--------|--------|------|
| レビュー依頼自動化 | **Recall** | 0.892 | **1.000** | 50proj |
| レビュアーランキング | **AUC-ROC** | **0.833** | 0.701 | 20proj |
| バランス重視 | **F1** | 0.871 | **0.905** | 50proj |

**50プロジェクトモデルの強み:**
- 承諾されるレビューを**1件も見逃さない**
- 実務では「送りすぎ」より「送り忘れ」の方が問題
- F1の向上はこのトレードオフが適切であることを示す

## 4. 時間的ロバスト性の詳細分析

### 4.1 最良パターン（6-9m期間）

**訓練6-9m → 評価6-9m:**
- F1: **0.948**（全実験中最高）
- AUC-ROC: 0.745
- Precision: 0.902
- Recall: 1.000

**理由:**
1. データ量が十分（レビュー蓄積が進んだ時期）
2. 開発活動が安定（プロジェクト文化が確立）
3. ボットアカウント除外が効果的に機能

### 4.2 最悪パターン（9-12m期間のクロス評価）

**訓練0-3m → 評価9-12m:**
- F1: 0.878
- AUC-ROC: **0.550**（ランダムに近い）

**原因仮説:**
1. 2年間のギャップで開発者・プロジェクト文化が変化
2. 2023年後半特有のイベント（リリースサイクル等）
3. データ分布の季節性

### 4.3 時間的劣化パターン

**2021年モデル（0-3m）の経年劣化:**

| 評価期間 | 訓練からの経過 | AUC-ROC | 劣化率 |
|----------|---------------|---------|--------|
| 0-3m | 0ヶ月 | 0.685 | 0% |
| 3-6m | 3ヶ月 | 0.677 | -1.2% |
| 6-9m | 6ヶ月 | 0.672 | -1.9% |
| 9-12m | 9ヶ月 | 0.550 | **-19.7%** |

**観察:**
- 6ヶ月まで安定（劣化2%未満）
- 9ヶ月以降急激に劣化
- **推奨: 6ヶ月ごとの再学習**

## 5. プロジェクト多様性の影響

### 5.1 48プロジェクトの内訳

**Tier 1（Interop必須コア）: 25プロジェクト**
- Nova, Neutron, Cinder, Swift, Keystone, Glance, Horizon等

**Tier 2（重要サービス）: 15プロジェクト**
- Heat, Ironic, Octavia, Manila, Barbican, Designate等

**Tier 3（インフラ・SDK）: 7プロジェクト**
- OpenStackSDK, Oslo.*, Requirements等

**Tier 4（デプロイメント）: 3プロジェクト**
- Kolla, Kolla-Ansible, DevStack

### 5.2 多様性の定量化

**開発者分布:**
- 総開発者数: 1,855名
- プロジェクトあたり平均: 38.6名
- クロスプロジェクト開発者: 不明（要分析）

**レビュー分布:**
- 総レビュー数: 119,010件
- プロジェクトあたり平均: 2,479件
- 正例率: 不明（要分析）

## 6. 結論と推奨事項

### 6.1 主要な結論

1. **50プロジェクトモデルはF1で20プロジェクトを上回る（0.905 vs 0.871）**
   - Recall完全化（1.000）が主要因
   - Precisionわずか低下（-1.8pp）は許容範囲

2. **AUC-ROC低下（0.701 vs 0.833）は実用上問題ない**
   - 二値分類性能（F1）が重要
   - ランキング性能低下はプロジェクト多様性のトレードオフ

3. **2xオーバーサンプリングが最適**
   - No OSと性能差わずか（+0.3pp）
   - 3x OSは過学習の兆候

4. **時間的ロバスト性は6ヶ月まで**
   - 6ヶ月以降急激に劣化（-19.7%）
   - 定期的な再学習が必要

### 6.2 実用上の推奨事項

#### ユースケース1: レビュー依頼自動化
**推奨モデル:** 50プロジェクト（2x OS）
- Recall=1.0で見逃しゼロ
- 6-9m期間モデル（F1=0.948）

#### ユースケース2: レビュアーランキング
**推奨モデル:** 20プロジェクト
- AUC-ROC=0.833で順序性能高い
- 確信度スコアが信頼できる

#### ユースケース3: プロジェクト横断分析
**推奨モデル:** 50プロジェクト
- より広範なパターン学習
- クロスプロジェクト活動の影響を捉える

### 6.3 今後の改善方向

1. **階層的モデリング**
   - Tier別サブモデル → 統合予測
   - プロジェクト特有パターンとグローバルパターンを分離

2. **時間的劣化対策**
   - オンライン学習・増分学習
   - 季節性・トレンドの明示的モデリング

3. **特徴量拡張**
   - パス類似度30次元の活用（現在未使用）
   - プロジェクト埋め込み（Project2Vec等）

4. **負例サンプリング改善**
   - ハードネガティブマイニング
   - プロジェクト別負例バランス調整

## 7. 統計的有意性

### 7.1 データ量

| メトリクス | 20プロジェクト | 50プロジェクト | 比率 |
|-----------|---------------|---------------|------|
| レビュー数 | 不明 | 119,010 | - |
| 開発者数 | 不明 | 1,855 | - |
| プロジェクト数 | 20 | 48 | 2.4x |
| 評価サンプル | 149 | 225 | 1.5x |

### 7.2 性能差の信頼区間

**F1差分: +3.7pp（0.871 → 0.905）**
- サンプル数: 225（50proj）vs 149（20proj）
- 統計的有意性: 要検定（bootstrap等）

**AUC-ROC差分: -13pp（0.833 → 0.701）**
- 実質的な差異（effect size大）
- プロジェクト多様性の影響が支配的

---

**作成日:** 2025-12-14
**実験:** 50プロジェクト IRL学習（Cross-Temporal）
**データ:** 2021-2024 OpenStack (48 projects, 119,010 reviews)
