# レビュー承諾予測モデル　分析結果（Phase 2 & 4）

## 実行日: 2025-12-14

---

## Phase 2: モデル比較分析結果

### モデル性能サマリー

| Model | F1 | Precision | Recall | AUC-ROC | AUC-PR |
|-------|-----|-----------|--------|---------|--------|
| **50proj_improved (no_os)** | **0.908** | 0.832 | **1.000** | 0.691 | 0.907 |
| **50proj (2x_os)** | **0.908** | 0.833 | 0.999 | **0.703** | 0.909 |
| **50proj (no_os)** | **0.907** | 0.831 | **1.000** | **0.701** | **0.909** |
| 50proj_improved (2x_os) | 0.905 | 0.833 | 0.991 | 0.677 | 0.903 |
| 50proj (3x_os) | 0.905 | 0.840 | 0.982 | **0.701** | 0.909 |
| 50proj_improved (3x_os) | 0.896 | 0.843 | 0.961 | 0.685 | 0.907 |
| **20 Projects** | 0.871 | 0.851 | 0.892 | **0.833** | **0.914** |

---

### 主要な発見

#### 1. 50プロジェクトモデルはF1で20プロジェクトを大幅に上回る

**F1スコアの比較:**
- **50proj (best)**: 0.908（+3.7pp vs 20proj）
- 20proj: 0.871

**原因:**
- **Recall完全化**: 50projでは1.000（20projは0.892）
  - 承諾されるレビューを**1件も見逃さない**
  - より多様なプロジェクトデータで承諾パターンを網羅的に学習

- **Precisionは微減**: 0.832（20projは0.851, -1.9pp）
  - より多くの偽陽性を許容
  - 実用的には「送りすぎ」＜「送り忘れ」なので許容範囲

---

#### 2. AUC-ROCは20プロジェクトが優位

**AUC-ROCの比較:**
- **20proj**: 0.833（最高）
- **50proj (best)**: 0.703（-13pp）
- 50proj_improved: 0.677-0.691（さらに低下）

**原因分析:**

##### (1) プロジェクト多様性の増加
- 50プロジェクトでは異なる文化・プラクティスが混在
- 予測スコアが中央に集まる（分散減少）
  - 20proj: min=0.383, max=0.777, std=0.107
  - 50proj: より狭い範囲に集中（推定）

##### (2) ランキング性能 vs 分類性能のトレードオフ
- **AUC-ROC（ランキング）**: 「誰が最も承諾しやすいか」の順序
  - 20proj: 順序が明確（確信度に差がある）
  - 50proj: 順序が不明確（確信度が均質化）

- **F1（分類）**: 「承諾するかしないか」の二値判定
  - 20proj: 0.871
  - **50proj: 0.908（優位）**

**結論**: 50projは二値分類で優れるが、ランキングでは劣る

---

#### 3. パラメータ調整（改善版）の効果は限定的

**改善版パラメータ:**
- エポック数: 20 → 50
- 学習率: 0.0001 → 0.0003
- Focal Loss: alpha=0.3, gamma=2.0（固定）

**結果:**
| 設定 | F1（元） | F1（改善版） | AUC-ROC（元） | AUC-ROC（改善版） |
|------|---------|-------------|---------------|------------------|
| no_os | 0.907 | **0.908** (+0.1pp) | **0.701** | 0.691 (-1pp) |
| 2x_os | **0.908** | 0.905 (-0.3pp) | **0.703** | 0.677 (-2.6pp) |
| 3x_os | **0.905** | 0.896 (-0.9pp) | **0.701** | 0.685 (-1.6pp) |

**観察:**
- **F1**: ほぼ変化なし（±0.3pp以内）
- **AUC-ROC**: **むしろ低下**（-1~-2.6pp）

**原因仮説:**
1. **Focal Loss alpha=0.3が過剰**
   - 元のauto調整（alpha=0.4-0.55）の方が適切
   - alpha=0.3は負例を過度に重視し、スコア分散を減少させた

2. **gamma=2.0の影響**
   - 難しい例（境界付近）により焦点を当てる
   - 結果、境界付近のスコアが増加し、明確な区別が困難に

3. **エポック50の過学習**
   - 訓練データに過適応
   - 汎化性能（AUC-ROC）が低下

**結論**: **元のパラメータ（auto調整）が最適**

---

#### 4. オーバーサンプリングの最適設定

| 設定 | F1（平均） | AUC-ROC（平均） | Recall（平均） |
|------|-----------|----------------|---------------|
| **2x OS** | **0.908** | **0.703** | 0.999 |
| No OS | 0.908 | 0.701 | **1.000** |
| 3x OS | 0.905 | 0.701 | 0.982 |

**結論**: **2x オーバーサンプリングが最適**
- No OSとほぼ同等のF1
- AUC-ROCがわずかに高い（+0.2pp）
- 3x OSは過学習の兆候（Recall低下）

---

## Phase 4: 誤予測パターン分析結果

### 予測分類の分布

| 分類 | 件数 | 割合 |
|------|------|------|
| **True Positive (TP)** | 899,847 | **91.9%** |
| **False Positive (FP)** | 78,787 | **8.1%** |
| True Negative (TN) | 0 | 0% |
| False Negative (FN) | 0 | 0% |

**総予測数**: 978,634件

---

### 重要な発見

#### 1. False Negative（見逃し）がゼロ！

**意味:**
- 承諾するレビュアーを**1人も見逃していない**
- Recall = 1.000の実証

**実用的価値:**
- レビュー依頼自動化において最も重要
- 「送り忘れ」によるレビュー遅延を完全に回避

---

#### 2. False Positiveの特性

**総数**: 78,787件（全体の8.1%）

**主な特徴:**
- **クロスプロジェクト活動率: 89.0%**
  - 非常に高い横断活動
  - 複数プロジェクトで活動する開発者の予測が難しい

**FPが発生する理由（仮説）:**

1. **プロジェクト移行中**
   - メインプロジェクトが変わったタイミング
   - 過去の活動パターンが突然変化

2. **負荷急増**
   - 複数プロジェクトで同時に依頼増加
   - キャパシティを超えて拒否

3. **季節性**
   - リリース前後で活動パターンが変化
   - 特定期間のみ活発（データに表れにくい）

4. **燃え尽き**
   - 過去の高活動が急激に低下
   - モデルは過去のパターンに基づき高スコアを付与

---

#### 3. 誤予測の影響評価

**Precision = 0.832**
- 100件のレビュー依頼推奨のうち、約17件は不要
- **許容可能な範囲**:
  - 「送りすぎ」は「送り忘れ」より問題が小さい
  - レビュアーは無視できる（強制ではない）
  - Recall=1.000の恩恵が大きい

**実務への影響:**
- レビュー依頼自動化において、FP 8%は許容範囲
- むしろFN=0%の方が重要

---

## 総合考察

### RQ1: プロジェクト数の増加は予測性能を向上させるか？

**答え: YES（F1）, NO（AUC-ROC）**

| メトリクス | 20 Projects | 50 Projects | 判定 |
|-----------|-------------|-------------|------|
| **F1** | 0.871 | **0.908** | ✅ **向上（+3.7pp）** |
| **AUC-ROC** | **0.833** | 0.703 | ❌ **低下（-13pp）** |
| **Recall** | 0.892 | **1.000** | ✅ **完全化** |
| Precision | **0.851** | 0.832 | ⚠️ 微減（-1.9pp） |

**結論:**
- **二値分類タスク（F1）**: 50プロジェクトが優位
- **ランキングタスク（AUC-ROC）**: 20プロジェクトが優位

---

### RQ2: ユースケース別の推奨モデル

| ユースケース | 推奨モデル | 理由 |
|-------------|-----------|------|
| **レビュー依頼自動化** | **50proj (2x_os)** | Recall=1.000、見逃しゼロ |
| **レビュアーランキング** | **20 Projects** | AUC-ROC=0.833、順序性能高い |
| **バランス重視** | **50proj (no_os)** | F1=0.908、総合性能最高 |

---

### RQ3: パラメータ調整の有効性

**答え: 今回の調整は効果なし**

**改善版の結果:**
- F1: ±0.3pp（ほぼ変化なし）
- AUC-ROC: -1~-2.6pp（むしろ低下）

**原因:**
- Focal Loss の過度な調整（alpha=0.3, gamma=2.0）
- エポック50での過学習

**推奨:**
- **元のauto調整パラメータを維持**
- エポック20で十分
- オーバーサンプリング2xが最適

---

### RQ4: False Positiveの実用的影響

**答え: 許容可能**

**FP率: 8.1%**
- 100件推奨中、約8件は不要
- レビュアーは無視可能
- **FN=0%の恩恵が大きい**（見逃しゼロ）

**FPの主要原因:**
- クロスプロジェクト活動（89%）
- プロジェクト移行・負荷変動・季節性

**改善方向:**
- プロジェクト間の遷移モデリング
- 時系列での活動変化検出
- 外部要因（リリーススケジュール等）の組み込み

---

## 可視化結果

### 生成された図

1. **モデル比較レーダーチャート**
   - [visualizations/model_comparison_radar.png](../outputs/visualizations/model_comparison_radar.png)
   - 5モデルの6指標比較

2. **メトリクス別棒グラフ**
   - [visualizations/model_comparison_bars.png](../outputs/visualizations/model_comparison_bars.png)
   - F1, Precision, Recall, AUC-ROC, AUC-PRの詳細比較

3. **エラー分析**
   - [visualizations/error_analysis.png](../outputs/visualizations/error_analysis.png)
   - 混同行列、予測分類分布、エラー分布

---

## データセット

### 生成されたCSV

1. **モデル比較サマリー**
   - [analysis_data/model_comparison_summary.csv](../outputs/analysis_data/model_comparison_summary.csv)

2. **False Positiveケース**
   - [analysis_data/false_positive_cases.csv](../outputs/analysis_data/false_positive_cases.csv)
   - 78,787件のFP詳細

3. **全エラーケース**
   - [analysis_data/all_error_cases.csv](../outputs/analysis_data/all_error_cases.csv)

---

## 今後の分析方向

### Phase 3の実装（保留中）

**課題:**
- 14次元状態特徴量がCSVに直接含まれていない
- IRLモデル内部で動的計算される特徴量

**解決策:**
1. IRLモデルから特徴量を抽出する専用スクリプト作成
2. 予測時の状態ベクトルをログ出力
3. 特徴量エンジニアリングの再実装

**期待される分析:**
- 的中率セグメント別の14次元特徴量比較
- PCA散布図（的中率でカラーマップ）
- プロジェクト数と予測精度の関係

### その他の深堀り分析

1. **時系列での誤予測パターン**
   - FPが発生する時期（リリース前/後等）
   - 季節性の定量化

2. **プロジェクト別の予測精度**
   - 48プロジェクトごとのF1, AUC-ROC
   - プロジェクトの特性と精度の関係

3. **開発者タイプ別の予測精度**
   - 専門型（1 proj） vs 横断型（4+ proj）
   - 経験日数との関係

4. **SHAP値による解釈**
   - 各特徴量の予測への寄与度
   - プロジェクト横断特徴量の重要性

---

**作成日**: 2025-12-14
**分析対象**: 50プロジェクト IRL学習（元 & 改善版）
**データ**: 2021-2024 OpenStack (48 projects, 119,010 reviews)
