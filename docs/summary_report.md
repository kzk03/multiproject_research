# Issue Report Localization 実験結果サマリー

## エグゼクティブサマリー

本研究では、Issue Report Localization（IRL）タスクにおいて、**単一プロジェクト vs 複数プロジェクト**、および**オーバーサンプリングの効果**を詳細に分析した。

### 主要な発見

1. **複数プロジェクト（オーバーサンプリングなし）は極めて高い性能を示すが、これはデータの極端な不均衡に起因**
   - F1スコア: 0.918（同一期間）、0.900（未来期間）
   - Recall: 完全に1.0（すべてのバグ関連イシューを検出）
   - しかし、AUC-ROCは低く（0.635、0.527）、実際の識別能力は限定的

2. **オーバーサンプリング（2倍）により、より現実的で安定した性能を達成**
   - F1スコア: 0.654（同一期間）、0.638（未来期間）
   - Recall: 0.924と高い検出率を維持
   - AUC-ROC: 0.697と良好な識別能力
   - より均衡したPrecision-Recallバランス

3. **単一プロジェクトは時系列で性能が向上する傾向**
   - 汎化率: 105.44%（未来期間で性能向上）
   - AUC-ROC: 0.754（同一期間）→ 0.832（未来期間）
   - プロジェクトの成熟に伴うイシュー報告の標準化を示唆

---

## 詳細な性能比較

### 1. 同一期間での性能（訓練データと同じ時期での評価）

| 設定 | F1 | Precision | Recall | AUC-ROC |
|------|----|-----------| -------|---------|
| **Single Project (Nova)** | 0.636±0.058 | 0.602±0.101 | 0.717±0.171 | **0.754±0.051** |
| **Multi-Project (No OS)** | **0.918±0.046** | **0.852±0.078** | **1.000±0.000** | 0.635±0.051 |
| **Multi-Project (2x OS)** | 0.654±0.042 | 0.508±0.050 | 0.924±0.022 | 0.697±0.034 |
| **Multi-Project (3x OS)** | 0.655±0.030 | 0.513±0.036 | 0.908±0.005 | 0.712±0.023 |

**解釈：**
- Multi-Project (No OS)の極めて高いスコアは、positive率89.9%という極端な不均衡に起因
- オーバーサンプリングによりクラス分布が均衡化（positive率51.5%）
- Single Projectは最も高いAUC-ROCを示し、優れた識別能力を持つ

### 2. 未来期間での性能（訓練データより後の時期での評価）

| 設定 | F1 | Precision | Recall | AUC-ROC |
|------|----|-----------| -------|---------|
| **Single Project (Nova)** | 0.671±0.067 | 0.689±0.065 | 0.686±0.159 | **0.832±0.059** |
| **Multi-Project (No OS)** | **0.900±0.055** | **0.824±0.094** | **1.000±0.000** | 0.527±0.135 |
| **Multi-Project (2x OS)** | 0.638±0.021 | 0.484±0.021 | 0.939±0.041 | 0.696±0.048 |
| **Multi-Project (3x OS)** | 0.634±0.015 | 0.489±0.017 | 0.903±0.028 | 0.700±0.037 |

**解釈：**
- Multi-Project (No OS)は未来期間でもRecall=1.0を維持するが、AUC-ROCが大幅に低下（0.527）
- Single Projectは未来期間でAUC-ROCが向上（0.754→0.832）、時系列での改善を示す
- オーバーサンプリングありの設定は、最も低い標準偏差で安定した性能

### 3. 汎化性能分析

| 設定 | F1低下 | 汎化率 | 解釈 |
|------|--------|--------|------|
| **Single Project (Nova)** | **-0.035** | **105.44%** | 未来期間で性能向上 |
| **Multi-Project (No OS)** | +0.018 | 98.08% | わずかな性能低下 |
| **Multi-Project (2x OS)** | +0.015 | 97.66% | 安定した汎化 |
| **Multi-Project (3x OS)** | +0.021 | 96.76% | 安定した汎化 |

**重要な観察：**
- Single Projectのみが未来期間で性能向上（汎化率105%超）
- これは、プロジェクトの成熟またはイシュー報告の標準化を示唆
- 複数プロジェクト設定は時系列変化に対してロバスト

---

## オーバーサンプリングの詳細分析

### クラス分布の変化

**オーバーサンプリングなし（2020_2024）：**
```
train_0-3m/eval_0-3m: 62+ / 7-  (89.9% positive)
train_3-6m/eval_3-6m: 59+ / 15- (79.7% positive)
train_6-9m/eval_6-9m: 62+ / 3-  (95.4% positive)
train_9-12m/eval_9-12m: 53+ / 18- (74.6% positive)
```

**2倍・3倍オーバーサンプリング：**
```
train_0-3m/eval_0-3m: 51+ / 48- (51.5% positive)
train_3-6m/eval_3-6m: 47+ / 50- (48.5% positive)
train_6-9m/eval_6-9m: 43+ / 59- (42.2% positive)
train_9-12m/eval_9-12m: 54+ / 59- (47.8% positive)
```

### オーバーサンプリングの効果

| 指標 | No OS | 2x OS | 3x OS | 解釈 |
|------|-------|-------|-------|------|
| **同一期間F1** | 0.918 | 0.654 | 0.655 | より現実的な評価環境 |
| **未来期間F1** | 0.900 | 0.638 | 0.634 | 安定した汎化性能 |
| **同一期間AUC-ROC** | 0.635 | 0.697 | **0.712** | 識別能力の向上 |
| **未来期間AUC-ROC** | 0.527 | 0.696 | **0.700** | ロバストな識別 |
| **RecallのSD** | 0.000 | 0.022 | 0.005 | より多様な予測 |

**重要な洞察：**

1. **オーバーサンプリングは単なる性能向上ではなく、評価環境の変更**
   - クラス分布が劇的に変化（89.9% → 51.5% positive）
   - より現実的でバランスの取れた評価が可能に

2. **AUC-ROCの大幅な改善**
   - No OS: 0.635 → 2x OS: 0.697 → 3x OS: 0.712（同一期間）
   - モデルの実際の識別能力が向上

3. **Recall-Precisionバランスの改善**
   - No OS: Recall=1.0（すべてpositiveと予測）
   - 2x/3x OS: Recall=0.90-0.92（より適切な閾値判断）

4. **2倍 vs 3倍の比較**
   - 性能差は非常に小さい（F1で0.001-0.005）
   - 3倍の方がAUC-ROCでわずかに優位
   - 過学習リスクを考慮すると**2倍で十分**

---

## 時系列パターンの詳細分析

### Single Project (Nova) の特徴的パターン

**最高性能を示す組み合わせ：**
1. train_0-3m → eval_6-9m: **F1=0.774, AUC=0.910**
2. train_9-12m → eval_9-12m: F1=0.727
3. train_0-3m → eval_3-6m: F1=0.700

**解釈：**
- 初期データ（0-3m）が中期データ（6-9m）の予測に最適
- 時系列でデータの一貫性が向上している可能性
- プロジェクトの成熟に伴う標準化効果

### Multi-Project の時系列安定性

**安定性の指標（F1スコアの標準偏差）：**
- No OS: 0.046（同一期間）、0.055（未来期間）
- 2x OS: **0.042（同一期間）、0.021（未来期間）**
- 3x OS: **0.030（同一期間）、0.015（未来期間）**

**解釈：**
- オーバーサンプリングにより時系列での安定性が大幅に向上
- 3x OSが最も安定（SD=0.015）
- 複数ドメインからの学習が時系列変化に対してロバスト

---

## 実用的な推奨事項

### シナリオ別の最適設定

#### 1. 高いRecallが最優先（バグを絶対に見逃したくない）
**推奨**: Multi-Project (No Oversampling)
- Recall=1.0を達成
- すべてのバグ関連イシューを検出
- ただし、誤検知（False Positive）の増加を許容する必要

**適用例**：
- セキュリティクリティカルなプロジェクト
- 早期バグ検出が最重要な開発フェーズ

#### 2. バランスの取れた性能が重要
**推奨**: Multi-Project (2x Oversampling)
- F1=0.638-0.654と実用的
- Recall=0.924と高い検出率
- AUC-ROC=0.697と良好な識別能力
- 時系列で安定した性能（SD=0.021）

**適用例**：
- 一般的なソフトウェア開発プロジェクト
- 複数プロジェクトを横断するツール開発

#### 3. 単一プロジェクトでの長期運用
**推奨**: Single Project設定
- AUC-ROC=0.754-0.832と優れた識別能力
- 時系列で性能が向上する可能性（汎化率105%）
- プロジェクト固有のパターンを効果的に学習

**適用例**：
- 特定の大規模プロジェクトに特化したツール
- プロジェクト固有の文化やパターンが強い環境

#### 4. 最も安定した性能が必要
**推奨**: Multi-Project (3x Oversampling)
- 最も低い標準偏差（F1 SD=0.015）
- AUC-ROC=0.700-0.712と最高の識別能力
- 時系列変化に対して最もロバスト

**適用例**：
- エンタープライズ環境でのデプロイ
- 予測可能な性能が求められるサービス

---

## 学術的貢献

### 新しい発見

1. **極端なクラス不均衡の影響の定量化**
   - Positive率89.9%の環境では、すべてをpositiveと予測する戦略が最適化される
   - 高いF1スコアが必ずしも良いモデルを意味しない

2. **オーバーサンプリングの二重の役割**
   - 性能向上ではなく、より現実的な評価環境の構築
   - AUC-ROCの大幅な改善（0.635 → 0.712）

3. **時系列での性能向上現象**
   - 単一プロジェクトで汎化率105.44%を観測
   - プロジェクトの成熟に伴う標準化効果を示唆

4. **複数プロジェクト学習の安定性**
   - ドメイン多様性が時系列変化に対するロバスト性をもたらす
   - オーバーサンプリング併用で標準偏差0.015を達成

### 今後の研究方向

1. **評価プロトコルの改善**
   - オーバーサンプリングが評価データに与える影響の詳細調査
   - 同一の評価セットでの公平な比較手法の確立

2. **誤り分析の深化**
   - False Positiveの特性分析（どのようなイシューが誤検知されるか）
   - False Negativeのパターン分析（見逃されるバグの特徴）

3. **他の不均衡対処手法の比較**
   - SMOTE（Synthetic Minority Over-sampling Technique）
   - Cost-sensitive learning
   - Focal Lossなどの損失関数の工夫

4. **閾値最適化戦略の拡張**
   - F1最大化以外の基準（コスト最小化、ROI最大化など）
   - アプリケーション要件に応じた動的な閾値調整

5. **転移学習の詳細分析**
   - どのプロジェクトが学習に最も貢献しているか
   - プロジェクト間の類似度と転移学習効果の関係

---

## 結論

本研究により、Issue Report Localizationタスクにおいて：

1. **複数プロジェクト学習は有効**だが、クラス不均衡に細心の注意が必要
2. **オーバーサンプリング（2倍）は強く推奨**される
   - より現実的で安定した性能を提供
   - AUC-ROCの大幅な改善
3. **単一プロジェクト学習も十分に有効**
   - 特に、時系列での改善が期待できる環境
   - 優れた識別能力（AUC-ROC=0.832）
4. **評価指標の慎重な選択が重要**
   - F1スコアだけでなく、AUC-ROC、Recall-Precisionバランスを総合的に考慮
5. **時系列での安定性は複数プロジェクト学習の大きな利点**
   - 標準偏差0.015-0.021と非常に安定

実用アプリケーションでは、具体的な要件（Recall重視 vs バランス重視）、運用環境（単一 vs 複数プロジェクト）、リソース制約を考慮して、最適な設定を選択すべきである。

---

## 付録：生成された可視化

以下の可視化が`docs/figures/`に生成されています：

1. `performance_comparison.png` - 全設定の性能比較
2. `temporal_heatmaps.png` - 訓練期間×評価期間のF1スコアヒートマップ
3. `precision_recall_tradeoff.png` - Precision-Recallバランスの比較
4. `oversampling_effect.png` - オーバーサンプリング倍率による性能変化
5. `temporal_stability.png` - 時系列での性能安定性

これらの可視化により、実験結果の理解がより深まります。
